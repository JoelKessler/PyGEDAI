{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a1a2aa-bcb7-4fb7-91c4-a0eee75a882e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from collections import deque\n",
    "from queue import Queue, Empty\n",
    "\n",
    "from IPython.display import display, clear_output # for Jupyter updates\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.append(str(project_root))\n",
    "\n",
    "from pygedai.GEDAI_stream import gedai_stream, GEDAIStream\n",
    "\n",
    "import torch\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201189bd-1d0c-4710-9d81-1b82c3ad48ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _to_numpy(array_like):\n",
    "    if array_like is None:\n",
    "        return None\n",
    "    if isinstance(array_like, torch.Tensor):\n",
    "        return array_like.detach().cpu().float().numpy()\n",
    "    return np.asarray(array_like, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c88797-5a6b-48da-9a7b-1a2cdf5c59db",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RollingEEGPlot:\n",
    "    def __init__(self, fs: float, window_sec: float, n_channels: int, show_matlab: bool = True):\n",
    "        self.fs = float(fs)\n",
    "        self.window_sec = float(window_sec)\n",
    "        self.n_channels = max(int(n_channels), 1)\n",
    "        self.show_matlab = show_matlab\n",
    "\n",
    "        # Create figure and axes\n",
    "        self.fig, axes = plt.subplots(self.n_channels, 1, figsize=(10, 2.2 * self.n_channels), sharex=True)\n",
    "        if self.n_channels == 1:\n",
    "            axes = [axes]\n",
    "        self.axes = axes\n",
    "        self.lines_raw = []\n",
    "        self.lines_clean = []\n",
    "        self.lines_matlab = []\n",
    "\n",
    "        # vertical-line artists for each axis\n",
    "        self.vline_artists = [[] for _ in range(self.n_channels)]\n",
    "\n",
    "        for idx, ax in enumerate(self.axes):\n",
    "            raw_line, = ax.plot([], [], color=\"gray\", label=\"Raw EEG\", linewidth=1.5)\n",
    "            clean_line, = ax.plot([], [], color=\"blue\", label=\"Cleaned (Python)\", linewidth=1.0, linestyle=\"--\")\n",
    "            if self.show_matlab:\n",
    "                matlab_line, = ax.plot([], [], color=\"red\", label=\"Cleaned (MATLAB)\", linewidth=0.5, linestyle=\"-\")\n",
    "            else:\n",
    "                matlab_line = None\n",
    "            ax.set_ylabel(f\"Ch {idx}\")\n",
    "            ax.set_xlim(0.0, max(self.window_sec, 1.0))\n",
    "            ax.set_ylim(-1.0, 1.0)\n",
    "            if idx == 0:\n",
    "                ax.legend(loc=\"upper right\")\n",
    "            self.lines_raw.append(raw_line)\n",
    "            self.lines_clean.append(clean_line)\n",
    "            self.lines_matlab.append(matlab_line)\n",
    "\n",
    "        self.axes[-1].set_xlabel(\"Time (s)\")\n",
    "        self.fig.tight_layout()\n",
    "\n",
    "    def update(self,\n",
    "               raw_window: torch.Tensor,\n",
    "               cleaned_window: torch.Tensor,\n",
    "               matlab_window: Optional[torch.Tensor],\n",
    "               samples_processed: int,\n",
    "               recalib_times_sec: Optional[list] = None):\n",
    "\n",
    "        raw_np = _to_numpy(raw_window)[: self.n_channels]\n",
    "        clean_np = _to_numpy(cleaned_window)[: self.n_channels]\n",
    "        matlab_np = _to_numpy(matlab_window)[: self.n_channels] if (self.show_matlab and matlab_window is not None) else None\n",
    "\n",
    "        num_samples = raw_np.shape[1]\n",
    "        if num_samples == 0:\n",
    "            return\n",
    "\n",
    "        start_sample = max(int(samples_processed) - num_samples, 0)\n",
    "        time_axis = (np.arange(num_samples) + start_sample) / self.fs\n",
    "        right_edge = time_axis[-1]\n",
    "        left_edge = max(right_edge - self.window_sec, 0.0)\n",
    "\n",
    "        for idx, ax in enumerate(self.axes):\n",
    "            self.lines_raw[idx].set_data(time_axis, raw_np[idx])\n",
    "            self.lines_clean[idx].set_data(time_axis, clean_np[idx])\n",
    "\n",
    "            y_values = [raw_np[idx], clean_np[idx]]\n",
    "\n",
    "            if self.show_matlab:\n",
    "                if matlab_np is not None:\n",
    "                    self.lines_matlab[idx].set_data(time_axis, matlab_np[idx])\n",
    "                    y_values.append(matlab_np[idx])\n",
    "                else:\n",
    "                    self.lines_matlab[idx].set_data([], [])\n",
    "            elif self.lines_matlab[idx] is not None:\n",
    "                self.lines_matlab[idx].set_data([], [])\n",
    "\n",
    "            y_concat = np.concatenate(y_values)\n",
    "            y_min = float(np.min(y_concat))\n",
    "            y_max = float(np.max(y_concat))\n",
    "            pad = max((y_max - y_min) * 0.1, 1e-6)\n",
    "\n",
    "            ax.set_xlim(left_edge, max(right_edge, left_edge + 1.0 / self.fs))\n",
    "            ax.set_ylim(y_min - pad, y_max + pad)\n",
    "\n",
    "            # vertical green lines for threshold recalibrations\n",
    "            for artist in self.vline_artists[idx]:\n",
    "                artist.remove()\n",
    "            self.vline_artists[idx] = []\n",
    "\n",
    "            if recalib_times_sec is not None:\n",
    "                visible_times = [t for t in recalib_times_sec if left_edge <= t <= right_edge]\n",
    "                for t in visible_times:\n",
    "                    v = ax.axvline(t, color=\"green\", linestyle=\"--\", linewidth=1.0)\n",
    "                    self.vline_artists[idx].append(v)\n",
    "\n",
    "        self.fig.tight_layout()\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(self.fig)\n",
    "        plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e164fce-e881-4a59-a3d1-859397b627b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading and preprocessing\n",
    "raw_noise = mne.io.read_raw_eeglab(\"./samples/with_artifacts/empirical_NOISE_EOG_EMG.set\", preload=True)\n",
    "matlab_cleaned_raw_noise = mne.io.read_raw_eeglab(\"./samples/matlab_cleaned/cleaned_empirical_NOISE_EOG_EMG.set\", preload=True)\n",
    "\n",
    "raw_noise.set_eeg_reference(ref_channels='average', projection=False, verbose=False)\n",
    "matlab_cleaned_raw_noise.set_eeg_reference(ref_channels='average', projection=False, verbose=False)\n",
    "\n",
    "device = \"cpu\"\n",
    "noise_eeg = torch.from_numpy(raw_noise.get_data(picks=\"eeg\")).float()\n",
    "noise_matlab_cleaned = torch.from_numpy(matlab_cleaned_raw_noise.get_data(picks=\"eeg\")).float()\n",
    "\n",
    "leadfield_cov = torch.from_numpy(np.load(\"./leadfield_calibrated/leadfield4GEDAI_eeg_27ch.npy\")).float()\n",
    "fs = float(raw_noise.info[\"sfreq\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d105b-d183-4592-8bea-f78f4981437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_duration_sec = 0.03\n",
    "samples_per_chunk = max(int(round(fs * chunk_duration_sec)), 1)\n",
    "\n",
    "total_samples = noise_eeg.shape[1]\n",
    "num_chunks = total_samples // samples_per_chunk\n",
    "if num_chunks == 0:\n",
    "    raise ValueError(\"Not enough samples to form even a single 0.1 s chunk.\")\n",
    "\n",
    "usable_samples = num_chunks * samples_per_chunk\n",
    "\n",
    "eeg_for_stream = noise_eeg[:, :usable_samples].contiguous()\n",
    "matlab_for_stream = noise_matlab_cleaned[:, :usable_samples].contiguous()\n",
    "\n",
    "samples_per_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc59b814-e925-48ef-8b88-8bbaf9567209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape: (num_chunks, n_channels, samples_per_chunk)\n",
    "eeg_stream = eeg_for_stream.view(noise_eeg.shape[0], num_chunks, samples_per_chunk).permute(1, 0, 2).contiguous()\n",
    "matlab_stream = matlab_for_stream.view(noise_eeg.shape[0], num_chunks, samples_per_chunk).permute(1, 0, 2).contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4da954-853a-463b-93fd-54a49a692373",
   "metadata": {},
   "source": [
    "# Blocking calls with next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e3666-9855-4f37-a796-f18a6e6c7b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "state = None\n",
    "window_sec = 4.0\n",
    "plot_channels = min(5, noise_eeg.shape[0])\n",
    "\n",
    "# how many 0.1 s chunks to actually stream\n",
    "max_chunks = eeg_stream.shape[0]\n",
    "\n",
    "initial_threshold_delay = 10.0 # in seconds\n",
    "threshold_update_interval = 10.0 # in seconds\n",
    "\n",
    "plotter = RollingEEGPlot(fs=fs, window_sec=window_sec, n_channels=plot_channels, show_matlab=True)\n",
    "\n",
    "# precompute threshold recalibration times (in seconds)\n",
    "total_stream_time_sec = max_chunks * chunk_duration_sec\n",
    "recalibration_times_sec = []\n",
    "t = initial_threshold_delay\n",
    "while t <= total_stream_time_sec:\n",
    "    recalibration_times_sec.append(t)\n",
    "    t += threshold_update_interval\n",
    "\n",
    "window_capacity = max(int(round(window_sec / chunk_duration_sec)), 1)\n",
    "raw_window_chunks = deque(maxlen=window_capacity)\n",
    "cleaned_window_chunks = deque(maxlen=window_capacity)\n",
    "matlab_window_chunks = deque(maxlen=window_capacity)\n",
    "\n",
    "raw_history = []\n",
    "cleaned_history = []\n",
    "matlab_history = []\n",
    "\n",
    "eeg_cleaning_stream = gedai_stream(\n",
    "    sfreq=fs,\n",
    "    leadfield=leadfield_cov,\n",
    "    threshold_update_interval_sec=threshold_update_interval,\n",
    "    initial_threshold_delay_sec=initial_threshold_delay,\n",
    "    denoising_strength=\"auto\",\n",
    "    epoch_size_in_cycles=12.0,\n",
    "    lowcut_frequency=0.5,\n",
    "    max_concurrent_chunks=1\n",
    ")\n",
    "\n",
    "# Streaming loop: 0.1 second at a time\n",
    "with eeg_cleaning_stream:\n",
    "    for idx, (chunk, matlab_chunk) in enumerate(zip(eeg_stream[:max_chunks], matlab_stream[:max_chunks])):\n",
    "        # simulate real-time\n",
    "        time.sleep(chunk_duration_sec)\n",
    "    \n",
    "        cleaned = eeg_cleaning_stream.next(chunk)\n",
    "    \n",
    "        chunk_cpu = chunk.cpu()\n",
    "        cleaned_cpu = cleaned.cpu()\n",
    "        matlab_cpu = matlab_chunk.cpu()\n",
    "    \n",
    "        raw_history.append(chunk_cpu)\n",
    "        cleaned_history.append(cleaned_cpu)\n",
    "        matlab_history.append(matlab_cpu)\n",
    "    \n",
    "        raw_window_chunks.append(chunk_cpu)\n",
    "        cleaned_window_chunks.append(cleaned_cpu)\n",
    "        matlab_window_chunks.append(matlab_cpu)\n",
    "    \n",
    "        raw_window = torch.cat(list(raw_window_chunks), dim=1)\n",
    "        cleaned_window = torch.cat(list(cleaned_window_chunks), dim=1)\n",
    "        matlab_window = torch.cat(list(matlab_window_chunks), dim=1)\n",
    "    \n",
    "        samples_processed = (idx + 1) * samples_per_chunk\n",
    "        plotter.update(\n",
    "            raw_window,\n",
    "            cleaned_window,\n",
    "            matlab_window,\n",
    "            samples_processed,\n",
    "            recalib_times_sec=recalibration_times_sec\n",
    "        )\n",
    "    \n",
    "        if (idx + 1) % 50 == 0 or (idx + 1) == max_chunks:\n",
    "            print(f\"Processed {idx + 1} / {max_chunks} chunks\", end=\"\\r\")\n",
    "    \n",
    "    print(\"\\nStreaming complete.\")\n",
    "\n",
    "cleaned_full = torch.cat(cleaned_history, dim=1)\n",
    "raw_full = torch.cat(raw_history, dim=1)\n",
    "matlab_full = torch.cat(matlab_history, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ec66b-2c94-4036-a172-4fb83de7cd76",
   "metadata": {},
   "source": [
    "# Non blocking threaded calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035361dd-0cc0-4daa-8306-26bffd107dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "state = None\n",
    "window_sec = 4.0\n",
    "plot_channels = min(5, noise_eeg.shape[0])\n",
    "\n",
    "# how many 0.1 s chunks to actually stream\n",
    "max_chunks = eeg_stream.shape[0]\n",
    "chunk_duration_sec = samples_per_chunk / fs  # make sure this is defined once\n",
    "\n",
    "processing_window_sec_target = 2.0  # pass the same value to gedai_stream below\n",
    "chunks_per_block = max(int(round(processing_window_sec_target / chunk_duration_sec)), 1)\n",
    "samples_per_block = samples_per_chunk * chunks_per_block\n",
    "processing_window_sec = samples_per_block / fs\n",
    "if abs(processing_window_sec - processing_window_sec_target) > 1e-9:\n",
    "    print(\n",
    "        f\"Adjusted processing window to {processing_window_sec:.6f}s so it aligns with the chunk size \"\n",
    "        f\"(target was {processing_window_sec_target:.6f}s)\"\n",
    "    )\n",
    "\n",
    "initial_threshold_delay = 20.0  # in seconds\n",
    "threshold_update_interval = 20.0  # in seconds\n",
    "\n",
    "plotter = RollingEEGPlot(fs=fs, window_sec=window_sec, n_channels=plot_channels, show_matlab=True)\n",
    "\n",
    "# precompute threshold recalibration times (in seconds)\n",
    "total_stream_time_sec = max_chunks * chunk_duration_sec\n",
    "recalibration_times_sec = []\n",
    "t = initial_threshold_delay\n",
    "while t <= total_stream_time_sec:\n",
    "    recalibration_times_sec.append(t)\n",
    "    t += threshold_update_interval\n",
    "\n",
    "window_capacity = max(int(round(window_sec / chunk_duration_sec)), 1)\n",
    "raw_window_chunks = deque(maxlen=window_capacity)\n",
    "cleaned_window_chunks = deque(maxlen=window_capacity)\n",
    "matlab_window_chunks = deque(maxlen=window_capacity)\n",
    "\n",
    "raw_history = []\n",
    "cleaned_history = []\n",
    "matlab_history = []\n",
    "\n",
    "matlab_cache: dict[int, torch.Tensor] = {}\n",
    "result_queue: Queue[tuple[int, torch.Tensor, torch.Tensor]] = Queue()\n",
    "\n",
    "def handle_cleaned_chunk(cleaned_chunk: torch.Tensor, chunk_index: int, raw_chunk: torch.Tensor) -> None:\n",
    "    result_queue.put(\n",
    "        (\n",
    "            chunk_index,\n",
    "            cleaned_chunk.detach().cpu(),\n",
    "            raw_chunk.detach().cpu(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "def process_ready_results(block: bool = False) -> None:\n",
    "    while True:\n",
    "        try:\n",
    "            idx, cleaned_cpu, raw_cpu = result_queue.get(block=block, timeout=0.05 if block else 0.0)\n",
    "        except Empty:\n",
    "            break\n",
    "\n",
    "        if cleaned_cpu.size(1) != samples_per_block or raw_cpu.size(1) != samples_per_block:\n",
    "            raise ValueError(\n",
    "                \"Processing window returned unexpected sample counts; ensure processing_window_sec aligns with chunk size\"\n",
    "            )\n",
    "\n",
    "        block_start = idx * chunks_per_block\n",
    "        # gather the matching MATLAB slices for this block\n",
    "        matlab_parts = []\n",
    "        for offset in range(chunks_per_block):\n",
    "            matlab_parts.append(matlab_cache.pop(block_start + offset).cpu())\n",
    "        matlab_cpu_full = torch.cat(matlab_parts, dim=1)\n",
    "\n",
    "        # split the aggregated tensors back into original 0.1 s segments\n",
    "        cleaned_splits = cleaned_cpu.split(samples_per_chunk, dim=1)\n",
    "        raw_splits = raw_cpu.split(samples_per_chunk, dim=1)\n",
    "        matlab_splits = matlab_cpu_full.split(samples_per_chunk, dim=1)\n",
    "\n",
    "        for i, (clean_seg, raw_seg, matlab_seg) in enumerate(zip(cleaned_splits, raw_splits, matlab_splits)):\n",
    "            sample_idx = block_start + i\n",
    "\n",
    "            raw_history.append(raw_seg)\n",
    "            cleaned_history.append(clean_seg)\n",
    "            matlab_history.append(matlab_seg)\n",
    "\n",
    "            raw_window_chunks.append(raw_seg)\n",
    "            cleaned_window_chunks.append(clean_seg)\n",
    "            matlab_window_chunks.append(matlab_seg)\n",
    "\n",
    "            raw_window = torch.cat(list(raw_window_chunks), dim=1)\n",
    "            cleaned_window = torch.cat(list(cleaned_window_chunks), dim=1)\n",
    "            matlab_window = torch.cat(list(matlab_window_chunks), dim=1)\n",
    "\n",
    "            samples_processed = (sample_idx + 1) * samples_per_chunk\n",
    "            plotter.update(\n",
    "                raw_window,\n",
    "                cleaned_window,\n",
    "                matlab_window,\n",
    "                samples_processed,\n",
    "                recalib_times_sec=recalibration_times_sec,\n",
    "            )\n",
    "\n",
    "            if (sample_idx + 1) % 50 == 0 or (sample_idx + 1) == max_chunks:\n",
    "                print(f\"Processed {sample_idx + 1} / {max_chunks} chunks\", end=\"\\r\")\n",
    "                if (sample_idx + 1) == max_chunks:\n",
    "                    print(\"\\nStreaming complete.\")\n",
    "\n",
    "        result_queue.task_done()\n",
    "\n",
    "eeg_cleaning_stream = gedai_stream(\n",
    "    sfreq=fs,\n",
    "    leadfield=leadfield_cov,\n",
    "    threshold_update_interval_sec=threshold_update_interval,\n",
    "    initial_threshold_delay_sec=initial_threshold_delay,\n",
    "    denoising_strength=\"auto\",\n",
    "    epoch_size_in_cycles=12.0,\n",
    "    lowcut_frequency=0.5,\n",
    "    max_concurrent_chunks=-1,\n",
    "    num_workers=4,\n",
    "    processing_window_sec=processing_window_sec,\n",
    "    moving_window_chunk_sec=10.0\n",
    ")\n",
    "\n",
    "# Streaming loop: 0.1 second at a time\n",
    "with eeg_cleaning_stream:\n",
    "    for idx, (chunk, matlab_chunk) in enumerate(zip(eeg_stream[:max_chunks], matlab_stream[:max_chunks])):\n",
    "        matlab_cache[idx] = matlab_chunk.detach().clone()\n",
    "        eeg_cleaning_stream.next(chunk, callback=handle_cleaned_chunk)\n",
    "        process_ready_results(block=False)\n",
    "\n",
    "# Finish whatever is still in flight\n",
    "while len(cleaned_history) < max_chunks:\n",
    "    process_ready_results(block=True)\n",
    "\n",
    "cleaned_full_concurrent = torch.cat(cleaned_history, dim=1)\n",
    "raw_full_concurrent = torch.cat(raw_history, dim=1)\n",
    "matlab_full_concurrent = torch.cat(matlab_history, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d619ed9b-2d06-4e7b-b68d-c263f5308712",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "state = None\n",
    "window_sec = 4.0\n",
    "plot_channels = min(5, noise_eeg.shape[0])\n",
    "\n",
    "max_chunks = eeg_stream.shape[0]\n",
    "initial_threshold_delay = 20.0\n",
    "threshold_update_interval = 20.0\n",
    "\n",
    "total_stream_time_sec = max_chunks * chunk_duration_sec\n",
    "recalibration_times_sec = []\n",
    "t = initial_threshold_delay\n",
    "while t <= total_stream_time_sec:\n",
    "    recalibration_times_sec.append(t)\n",
    "    t += threshold_update_interval\n",
    "\n",
    "window_capacity = max(int(round(window_sec / chunk_duration_sec)), 1)\n",
    "raw_window_chunks = deque(maxlen=window_capacity)\n",
    "cleaned_window_chunks = deque(maxlen=window_capacity)\n",
    "matlab_window_chunks = deque(maxlen=window_capacity)\n",
    "\n",
    "cleaning_times_ms = []\n",
    "\n",
    "eeg_cleaning_stream = gedai_stream(\n",
    "    sfreq=fs,\n",
    "    leadfield=leadfield_cov,\n",
    "    threshold_update_interval_sec=threshold_update_interval,\n",
    "    initial_threshold_delay_sec=initial_threshold_delay,\n",
    "    denoising_strength=\"auto\",\n",
    "    epoch_size_in_cycles=12.0,\n",
    "    lowcut_frequency=0.5,\n",
    "    max_concurrent_chunks=1,\n",
    "    moving_window_chunk_sec=1.0,\n",
    "    verbose_timing=False\n",
    ")\n",
    "\n",
    "with eeg_cleaning_stream:\n",
    "    for idx, (chunk, matlab_chunk) in tqdm(enumerate(\n",
    "        zip(eeg_stream[:max_chunks], matlab_stream[:max_chunks])\n",
    "    )):\n",
    "        start_t = time.time()\n",
    "        cleaned = eeg_cleaning_stream.next(chunk)\n",
    "        end_t = time.time()\n",
    "        \n",
    "        state = eeg_cleaning_stream.state\n",
    "        if (\n",
    "            state[\"initial_threshold_computed\"]\n",
    "            and state[\"samples_seen\"] > state[\"last_threshold_update_sample\"]\n",
    "        ):\n",
    "            cleaning_times_ms.append((end_t - start_t) * 1000.0)\n",
    "            \n",
    "        if (idx + 1) % 50 == 0 or (idx + 1) == max_chunks:\n",
    "            print(f\"Processed {idx + 1} / {max_chunks} chunks\", end=\"\\r\")\n",
    "        \n",
    "\n",
    "print(\"\\nStreaming complete.\")\n",
    "\n",
    "if cleaning_times_ms:\n",
    "    mean_ms = float(np.mean(cleaning_times_ms))\n",
    "    median_ms = float(np.median(cleaning_times_ms))\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar([\"mean\", \"median\"], [mean_ms, median_ms])\n",
    "    ax.set_ylabel(\"Cleaning time (ms)\")\n",
    "    ax.set_title(\"GEDAI chunk cleaning latency\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee09323-7c62-4461-9516-61705a2bd3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
